{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e567baa",
   "metadata": {},
   "source": [
    "# Diagnóstico Avanzado de Data Leakage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c31ec8",
   "metadata": {},
   "source": [
    "## Taxonomia de Data Leakage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16de5809",
   "metadata": {},
   "source": [
    "### Leakage temporal\n",
    "\n",
    "- **Definición formal:** Cuando dividimos nuestro dataset o hacemos k-fold validation, puede pasar que tengamos datos tanto de eventos del pasado como del futuro, haciendo que el modelo memorize lo que pasará en el futuro en lugar de predecirlo.\n",
    "- **Ejemplo concreto:** Cuando queremos crear un modelo que prediga las acciones del SP500 o de bitcoin. Lo ideal sería por ejemplo que el modelo aprendiera solamente con datos de 2020 a 2024 y nosotros probaramos con datos del 2025, el problema es que muchas veces no tienen en cuenta la componente temporal y simplemente dividen el dataset como cualquier otro conjunto. Esto ocasiona que el modelo si vea datos de 2025, de tal forma que uno puede creer que funciona muy bien pero la realidad es que no.\n",
    "- **Por qué es problemático:** El problema viene de hacernos creer que nuestro modelo es bastante bueno y que podemos predecir el futuro. Pero por ejemplo cuaando empezemos a usar el modelo con datos de 2026 no nos debería de sorprender que el modelo sea bastante malo.\n",
    "- **Cómo detectarlo:** El modelo funciona sorprendentemente bien, esto es bastante raro en series temporales. También si tuviste la mala idea de ponerlo en producción deberías de ver que funciona mucho peor a los resultados en test. Otra técnica es el análisis de los residuos entre el valor predicho y el real, se debería de ver como forma de ruido.\n",
    "- **Cómo prevenirlo:** Determinar un tiempo fijo, en donde de ese tiempo para atras solo sea para entrenar y de ese tiempo para adelante sea para probar el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f516207",
   "metadata": {},
   "source": [
    "### Leakage por Preprocesamiento\n",
    "\n",
    "- **Definición formal:** Es cuando le hacemos un preprocesamiento a los datos (imputar valores, transformaciones para el sesgo, escalamiento, etc) pero calculamos los valores con los que se hace el preprocesamiento (medias, desviaciones estandar, modas) con datos que deberían ir solo en test.\n",
    "- **Ejemplo concreto:** Imaginemos que tenemos una columna en donde nos falta 30% de nuestros datos, esta columna es numérica y decidimos imputarlos con la media. Decidimos calcular esta media sobre TODOS nuestros datos e imputar, después contentos dividimos ya nuestro dataset en una parte para entrenamiento y otra para prueba, este es un claro ejemplo de data leakage por preprocesamiento.\n",
    "- **Por qué es problemático:** El problema radica en que los datos de entrenamiento se ven influenciados por los datos de test, cuando esto no debería de pasar. Para el modelo cuando vea los datos de test deberían de serle completamente desconocidos, en cambio con data leakage por preprocesamiento aprendió algunas características de los datos de test y cuando es momento de inferir se le hace bastante facil obtener un altísimo rendimiento.\n",
    "- **Cómo detectarlo:** El modelo tiene un rendimiento demasiado bueno para ser verdad en los datos de test, practicamente igual al de entrenamiento. También si tenemos la mala suerte de ponerlo en producción se encontrará en esta ocasión con datos que ahora si nunca había visto y veremos que el rendimiento baja a comparacion del de test, esto en si no es malo si no es que se reporta normalmente cuanta confianza tiene el modelo, una confianza que no es verdadera.\n",
    "- **Cómo prevenirlo:** Definir Pipelines con skilearn por ejemplo ayuda bastamte, en la pipeline decidimos que transformaciones hacer y una vez que lo tenemos listo hay que dividir el dataset en entrenamiento y prueba. Es tan sencillo como usar pipeline.fit para entrenamiento y pieline.predict para los datos de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fd11fa",
   "metadata": {},
   "source": [
    "### Leakage por Target Encoding\n",
    "\n",
    "- **Definición formal:** Target encoding es una técnica que transforma variables categóricas en valores numéricos calculando estadísticas de la variable objetivo (por ejemplo, la media) para cada categoría. El leakage ocurre cuando estas estadísticas se calculan usando todo el dataset, incluyendo los datos de prueba, filtrando información del target que el modelo no debería conocer durante el entrenamiento.\n",
    "\n",
    "- **Ejemplo concreto:** Imaginemos que tenemos un dataset de clientes y queremos predecir si compran o no un producto. Tenemos una variable categórica llamada ciudad. Si calculamos la media de compra por ciudad usando todos los datos el modelo conocera la información de los clientes de prueba. Por ejemplo si en la ciudad de Hermosillo el 80% de los clientes compran el modelo va a aprenderse la proporción en vez de patrones generales.  \n",
    "- **Por qué es problemático:** El modelo parece muy preciso en entrenamiento y validación, pero falla en datos nuevos. Esto se debe a que aprendió información del target que solo estaba disponible en el dataset completo, lo que produce una evaluación inflada y resultados poco realistas.\n",
    "- **Cómo detectarlo:** Comparar desempeño entre entrenamiento y validación con datos “nuevos”: si hay un salto grande, podría indicar leakage. Revisar el pipeline de preprocesamiento: asegurarse de que estadísticas del target se calculen únicamente sobre el conjunto de entrenamiento, no usando datos futuros o de prueba.\n",
    "- **Cómo detectarlo:** Comparar desempeño entre entrenamiento y validación con datos “nuevos”: si hay un salto grande, podría indicar leakage. Revisar el pipeline de preprocesamiento: asegurarse de que estadísticas del target se calculen únicamente sobre el conjunto de entrenamiento, no usando datos futuros o de prueba.\n",
    "- **Cómo prevenirlo:** Calcular el target encoding solo con datos de entrenamiento. Para cada fold en validación cruzada, calcular las estadísticas solo con el fold de entrenamiento, no con el de prueba. Aplicar técnicas de suavizado o regularización en el target encoding para reducir la dependencia de categorías con pocas muestras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89663338",
   "metadata": {},
   "source": [
    "### Leakage por Features que contienen información futura\n",
    "\n",
    "- **Definición formal:** Ocurre cuando una característica (feature) incluye información que solo estaría disponible después del momento en que se hace la predicción. Es decir, el modelo recibe datos “del futuro” que no existirían en un escenario real, lo que provoca predicciones irreales y sobreajuste.\n",
    "- **Ejemplo concreto:** Si queremos predecir si un cliente pedirá un prestamo mañana e incluimos como feature saldo final del cliente en el banco mañana, estamos usando información que solo debería de conocerse después de la predicción, causando data leakage.\n",
    "- **Por qué es problemático:** El principal problema es la falsa ilusión de que el modelo funciona muy bien, pero en realidad no tiene capacidad de generalizar.\n",
    "- **Cómo detectarlo:** Revisamos el dataset y vemos si todas las características estarán disponibles cuando nos llegue un dato nuevo. También si hay alguna característica que tiene una correlacion muy alta con el target se podria estar filtrando información.\n",
    "- **Cómo prevenirlo:** Asegurarse de usar solo información disponible hasta el momento de la predicción. Implementar pipelines que respeten el tiempo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b99a50c",
   "metadata": {},
   "source": [
    "### Leakage por duplicación de registros\n",
    "\n",
    "- **Definición formal:** Ocurre cuando hay instancias iguales o casi identicas tanto en el conjunto de entrenamiento como en el conjunto de test. Esto provoca que cuando el modelo aprendio a predecir correctamente una instancia en entrenamiento y luego viene una de test igual el modelo la predecira correctamente pero no por la generalizacion sino porque ya la ha visto. \n",
    "- **Ejemplo concreto:** Supongamos que queremos predecir si una persona tiene cancer de pulmón. Ese paciente esta duplicado y esta tanto en train y en test. Entonces el modelo se fijará en las particularidades del paciente mas que en que es lo que hace que una persona tiene cancer\n",
    "- **Por qué es problemático:** Oculta problemas en la selección de características o el preprocesamiento. Da metricas infladas lo que da una falsa sensación de que el modelo funciona correctamente.\n",
    "- **Cómo detectarlo:** Revisar duplicados antes de separar nuestros datos de entrenamiento y de prueba. Analizar correlaciones altas entre train y test.\n",
    "- **Cómo prevenirlo:** Limpiando el dataset de duplicados antes de separar datos de entrenamiento y de prueba. También asegurarse que el mismo cliente quede ya sea en entrenamiento o en prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a773ab",
   "metadata": {},
   "source": [
    "### Leakage por estratificación incorrecta \n",
    "\n",
    "- **Definición formal:** Sucede cuando los datos de entrenamiento y prueba no se dividen correctamente, rompiendo la independencia entre ellos. Esto puede suceder si se estratifica mal el dataset o si hay duplicados o grupos relacionados que aparecen en ambos conjuntos, filtrando información del target entre entrenamiento y prueba.\n",
    "- **Ejemplo concreto:** Por ejemplo supongamos qu tenemos un dataset de clasificación. El objetivo es clasificar tipos de flores. Ademas supongamos que las clases no estan muy balanceadas, Si dividimos sin estratificar puede pasar que no haya instancias de una clase en el dataset de entrenamiento, así muy difícil para el modelo predecirlo.\n",
    "- **Por qué es problemático:** Si no utilizamos las metricas correctas el modelo puede parecer que funciona, ya que la clase mas grande eclipsa a las demás, dandonos una falsa impresión de que el modelo clasifica muy bien.\n",
    "- **Cómo detectarlo:** Revisar las distribuciones de las clases o de las características a estratificar, si la proporcion tanto en train como en test no es igual o muy parecida a la proporcion de todos los datos puede haber un problema de mal estratificado.\n",
    "- **Cómo prevenirlo:** Utilizar estratificación al dividir los datos, por ejemplo con train_test_split en scikit-learn, para mantener la proporción de cada clase. Verificar siempre la distribución de clases y grupos después de hacer el split, antes de entrenar el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adc898d",
   "metadata": {},
   "source": [
    "## Metodología para evitar el Data Leakage\n",
    "\n",
    "1. Dividir el dataset para entrenamiento y prueba \n",
    "- El paso mas importante para evitar el data leakage.\n",
    "- Asegurarnos de dividirlo estratíficadamente si es que lo necesita.\n",
    "- Asegurarnos de que hay una clara división en el tiempo para el caso de datos temporales. En pocas palabras, train es el pasado mientras test son los valores mas recientes.\n",
    "\n",
    "2. Preprocesamiento después de dividir el dataset\n",
    "- Asegurarse que la normalización, estandarización e imputación se calculen solo usando datos de entrenamiento.\n",
    "- Comprobar que no se calculen estadísticas globales antes de dividir los datos.\n",
    "\n",
    "3. Orden de las operaciones en el pipeline de preprocesamiento:\n",
    "- Verificar que todas las transformaciones y creaciones de feature se hagan después de dividir el dataset y solo se haga con la informacion de entrenamiento\n",
    "- Confirmar que la creación de features no filtra información en el conjunto de prueba por medio de las correlaciones.\n",
    "\n",
    "4. Características con correlación muy alta con el target\n",
    "- Revisar las correlaciones entre cada feature y el target\n",
    "- Revisar aquellas que tienen una correlacion mayor a 0.95 y analizar si hay información filtrada del target\n",
    "\n",
    "5. Características con información temportal o futura\n",
    "- Quedarse con características qu solo estarían disponibles con datos futuros.\n",
    "- Confirmar que las secuencias de tiempo respetan la causalidad y no se utilice información futura\n",
    "\n",
    "6. Duplicación de registros\n",
    "- Detectar si hay registros idénticos o casi idénticos en entrenamiento y prueba.\n",
    "- Si hay entidades repetidas usar splits por grupo para evitar que la información se filtre.\n",
    "\n",
    "7. Codificación\n",
    "- Verificar que target encoding u otros encodings que dependen del target se calculen solo en la parte de entrenamiento.\n",
    "- Verificcar que en prueba se apliquen las estadísticas aprendidas en entrenamiento, sin recalcular usando los datos de prueba.\n",
    "\n",
    "Esto es el pipeline general, a continuación se pone en forma de checklist.\n",
    "\n",
    "## Checklist para evitar el Data Leakage\n",
    "\n",
    "### 1. Dividir el dataset para entrenamiento y prueba\n",
    "- [ ] Dividir el dataset (paso más importante para evitar el data leakage).  \n",
    "- [ ] Dividir estratificadamente si es necesario.  \n",
    "- [ ] Asegurar clara división temporal para datos secuenciales: train = pasado, test = valores más recientes.\n",
    "\n",
    "### 2. Preprocesamiento después de dividir el dataset\n",
    "- [ ] Normalización, estandarización e imputación calculadas solo con datos de entrenamiento.  \n",
    "- [ ] No calcular estadísticas globales antes de dividir los datos.\n",
    "\n",
    "### 3. Orden de las operaciones en el pipeline de preprocesamiento\n",
    "- [ ] Todas las transformaciones y creación de features después de dividir el dataset y solo con información de entrenamiento.  \n",
    "- [ ] Confirmar que la creación de features no filtra información en el conjunto de prueba por medio de correlaciones.\n",
    "\n",
    "### 4. Características con correlación muy alta con el target\n",
    "- [ ] Revisar correlaciones entre cada feature y el target.  \n",
    "- [ ] Analizar features con correlación mayor a 0.95 para detectar filtración de información del target.\n",
    "\n",
    "### 5. Características con información temporal o futura\n",
    "- [ ] Mantener solo características que estarían disponibles con datos futuros.  \n",
    "- [ ] Confirmar que las secuencias de tiempo respeten la causalidad y no se use información futura.\n",
    "\n",
    "### 6. Duplicación de registros\n",
    "- [ ] Detectar registros idénticos o casi idénticos en entrenamiento y prueba.  \n",
    "- [ ] Si hay entidades repetidas, usar splits por grupo para evitar filtración de información.\n",
    "\n",
    "### 7. Codificación\n",
    "- [ ] Verificar que target encoding u otros encodings dependientes del target se calculen solo en la parte de entrenamiento.  \n",
    "- [ ] En prueba, aplicar estadísticas aprendidas en entrenamiento sin recalcular usando datos de prueba.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
